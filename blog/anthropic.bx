<?xml version='1.0' encoding='utf-8'?>
<blog>
<entry when='20240716T152100'>
<title>Anthropic</title>
<category>work</category>
<category>ai</category>

<description>I am starting a new job soon at Anthropic, the makers of the
Claude large language model.</description>

<body>

<p>I am starting a new job soon at
<a href="https://anthropic.com">Anthropic</a>, the makers of the
<a href="https://claude.ai">Claude</a> large language model.</p>

<p>It will be an interesting change for me, for a few reasons.  First, I know
essentially nothing about how LLMs work and are built.  Second, it's my first
new job in almost 12 years.  Third, I've been "between gigs" for six months,
so I have to get back to a work-day routine.</p>

<p>I have very mixed feelings about the tsunami-like rise of AI in the tech
world and beyond.  Large language models are clearly surprisingly powerful
tools, but they are also clearly being used in some not-great ways.  My main
concern is that people will use AI to make the world worse in various ways:
flooding information arenas with crappy bot slop, displacing human creative
effort with "it's good enough" machine-generated output, spewing disinformation
chaff, and so on.  Behind the scenes, the energy needs are substantial, which is
a big problem.</p>

<p>But every technology can be used for good or ill.  Anthropic is a public
benefit corporation with safety as a central mission.  AI and LLMs aren't going
away, so maybe I can help Anthropic pull towards the good.</p>

<p>I'm well outside my comfort zone at the moment, but whatever happens, it will
be an experience.</p>

</body>
</entry>
</blog>
